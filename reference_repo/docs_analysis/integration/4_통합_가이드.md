# Unity Perception × SynthDet × Unity Robotics 통합 가이드

Perception 분석 문서를 기반으로, `reference_repo/` 안의 **SynthDet**(샘플 프로젝트)과 **Unity-Robotics-Hub**(ROS/이동형 센서 연계)까지 함께 활용하는 방법을 정리한다.

---

## 1. 문서 목적

- Perception 패키지 분석 산출물(1~3장)을 **토대(Framework)** 로 사용
- SynthDet의 **실전 씬/Randomizer 구성**을 참고하여 바로 실행 가능한 예시 확보
- Unity-Robotics-Hub의 **ROS·이동형 카메라 파이프라인**을 결합해 Phase 2 선택 과제(로봇형 CCTV, ROS 스트림)를 준비

---

## 2. 자료 위치

| 분류 | 경로 | 핵심 내용 |
|------|------|-----------|
| Perception 분석 | `reference_repo/docs_analysis/` | 1~3장 + reference 문서 |
| Perception 코드 | `reference_repo/com.unity.perception/` | Runtime/Randomization, GroundTruth 등 |
| SynthDet | `reference_repo/SynthDet/` | Perception 기반 합성 데이터 샘플 프로젝트 |
| Unity Robotics | `reference_repo/Unity-Robotics-Hub/` | ROS-TCP, URDF Importer, SLAM 예제 |

---

## 3. 재사용 매트릭스

| 기능 축 | Perception | SynthDet | Unity-Robotics-Hub | 결합 전략 |
|---------|------------|----------|--------------------|-----------|
| **카메라/라벨링** | `PerceptionCamera`, `CameraLabeler` | 샘플 Labeler 구성 예시(63개 상품) | ROS Sensor Bridge (Camera msg) | Perception 패턴으로 CCTV Labeler 작성 → SynthDet 예시로 Scene/Prefab 구성 |
| **랜덤화/씬 구성** | Scenario/Randomizer 시스템 | 실제 Randomizer Prefab, Lighting/Material 세트 | 로봇 이동/URDF | Perception 기반 Custom Randomizer를 SynthDet Scene에 적용, 필요 시 로봇 카메라를 Robotics Hub로 제어 |
| **출력/데이터셋** | SOLO Endpoint, Message Builder | COCO 변환 튜토리얼, pysolotools | ROS Bag 변환 예제 | Phase1: SOLO→YOLO. Phase2: Robotics Hub 예제 참고해 ROS Topic으로 전송 |
| **군중/로봇 시뮬레이션** | 제공 없음 | 상품 배치/Anomaly 없음 | Navigation, SLAM, ROS Control | Crowd/Behavior는 우리 구현, Robot 카메라/이동은 Robotics Hub URDF·SLAM 예제로 보완 |

---

## 4. 통합 워크플로우

1. **Framework 파악** – `docs_analysis/1~3장`으로 Perception 패턴 이해  
2. **샘플 실행** – SynthDet README(`reference_repo/SynthDet/README.md`)의 Getting Started 절차로 Perception + Randomizer 구성 예시 실행  
3. **CCTV Scene 구성** – SynthDet의 Scene/Prefab을 참고하여 우리 Factory Scene에 PerceptionCamera, Labeler, Randomizer를 배치  
4. **Custom Labeler/Randomizer 구현** – `docs_analysis/3_개발자_참조.md` 코드 템플릿 사용  
5. **멀티 카메라/로봇 연계** – 필요 시 Unity-Robotics-Hub 튜토리얼(`tutorials/ros_unity_integration/README.md`)을 따라 ROS Publisher/Subscriber 설정 후, 이동형 카메라 데이터를 Perception 파이프라인과 동기화  
6. **데이터 Export/변환** – Perception SOLO 출력 → SynthDet 문서의 COCO 변환/pySOLOtools 가이드 적용 → Robotics Hub 예제 기반으로 ROS 메시지/Bag으로도 변환

---

## 5. 권장 액션 아이템

1. **SynthDet Scene 스냅샷 분석**  
   - 조명/배경 Randomizer와 Labeler 구성을 그대로 복사해 CCTV Scene 초기 템플릿 작성
2. **Perception Labeler 포크**  
   - `reference_repo/com.unity.perception/Runtime/GroundTruth/Labelers/BoundingBox/` 전체를 레포로 포크 → CCTV Labeler 네임스페이스에서 재사용
3. **ROS 연동 PoC**  
   - Unity-Robotics-Hub의 Pick-and-Place 튜토리얼을 따라 ROS-TCP 연결 확인  
   - 이동형 카메라 GameObject에 PerceptionCamera 추가, ROS Topic에 RGB 스트림 전송
4. **통합 README 업데이트**  
   - 메인 `docs/Concept` 또는 `docs/Design` 문서에 위 워크플로우를 요약, 팀별 역할/레포 연결을 명시

---

## 6. 참고 문서 링크

- Perception 분석: `reference_repo/docs_analysis/README.md`
- SynthDet 튜토리얼: `reference_repo/SynthDet/docs/GettingStartedSynthDet.md`
- COCO 변환: `reference_repo/SynthDet/docs/UnityProjectOverview.md` 및 `reference_repo/com.unity.perception/com.unity.perception/Documentation~/Tutorial/convert_to_coco.md`
- ROS 연동: `reference_repo/Unity-Robotics-Hub/tutorials/ros_unity_integration/README.md`

> **Tip**: Phase 1에서는 Perception + SynthDet 조합으로 빠르게 정적 CCTV Scene을 완성하고, Phase 2 선택 기능(로봇 카메라, SLAM)은 Unity-Robotics-Hub 예제를 통해 병렬 PoC로 진행한다.

